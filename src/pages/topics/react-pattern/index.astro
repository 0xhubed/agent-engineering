---
import BaseLayout from '../../../layouts/BaseLayout.astro';
import CodeBlock from '../../../components/CodeBlock.astro';
import Callout from '../../../components/Callout.astro';
import Table from '../../../components/Table.astro';
import Diagram from '../../../components/Diagram.astro';

const basicReactExample = [
  {
    language: 'pseudo',
    label: 'Pseudo-code',
    code: `function reactAgent(task, tools, maxSteps = 10):
    observations = []

    for step in range(maxSteps):
        # REASON: Generate thought about current state
        thought = llm.think(
            task: task,
            history: observations,
            prompt: "What should I do next to accomplish this task?"
        )

        # Check if task is complete
        if thought.indicatesCompletion:
            return extractFinalAnswer(thought, observations)

        # ACT: Select and execute action
        action = llm.selectAction(
            thought: thought,
            availableTools: tools
        )

        # OBSERVE: Get result from environment
        observation = execute(action)

        # Store for next iteration
        observations.append({
            thought: thought,
            action: action,
            observation: observation
        })

    return "Max steps reached without completion"`,
  },
  {
    language: 'python',
    label: 'Python (LangGraph)',
    code: `from langgraph.prebuilt import create_react_agent
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool

# Define tools
@tool
def search(query: str) -> str:
    """Search the web for information."""
    return web_search_api(query)

@tool
def calculator(expression: str) -> str:
    """Evaluate a mathematical expression."""
    return str(eval(expression))  # Use safe eval in production

# Create ReAct agent
llm = ChatOpenAI(model="gpt-4")
tools = [search, calculator]

agent = create_react_agent(llm, tools)

# Run the agent
result = agent.invoke({
    "messages": [
        ("user", "What's the population of France times 2?")
    ]
})

# The agent will:
# 1. Think: I need to find France's population
# 2. Act: search("population of France")
# 3. Observe: "67 million"
# 4. Think: Now I need to multiply by 2
# 5. Act: calculator("67000000 * 2")
# 6. Observe: "134000000"
# 7. Return: "France has ~67M people, doubled is 134M"`,
  },
  {
    language: 'csharp',
    label: 'C# (Agent Framework)',
    code: `using Microsoft.Extensions.AI;
using System.ComponentModel;

public class ReActAgent
{
    private readonly IChatClient _client;
    private readonly List<AITool> _tools;
    private readonly int _maxIterations;

    public ReActAgent(
        IChatClient client,
        List<AITool> tools,
        int maxIterations = 10)
    {
        _client = client;
        _tools = tools;
        _maxIterations = maxIterations;
    }

    public async Task<string> RunAsync(string task)
    {
        var messages = new List<ChatMessage>
        {
            new(ChatRole.System, GetSystemPrompt()),
            new(ChatRole.User, task)
        };

        for (int i = 0; i < _maxIterations; i++)
        {
            var response = await _client.GetResponseAsync(
                messages,
                new ChatOptions { Tools = _tools }
            );

            messages.Add(response.Message);

            // Check if agent is done (no tool calls)
            if (!response.Message.Contents
                .OfType<FunctionCallContent>().Any())
            {
                return response.Message.Text ?? "";
            }

            // Execute tool calls and add results
            foreach (var toolCall in response.Message.Contents
                .OfType<FunctionCallContent>())
            {
                var result = await ExecuteToolAsync(toolCall);
                messages.Add(new ChatMessage(
                    ChatRole.Tool,
                    result
                ));
            }
        }

        return "Max iterations reached";
    }

    private string GetSystemPrompt() => """
        You are a ReAct agent. For each step:
        1. THOUGHT: Reason about what to do next
        2. ACTION: Use a tool if needed
        3. OBSERVATION: Analyze the result
        Repeat until you can answer the user's question.
        """;
}`,
  },
];

const explicitReasoningExample = [
  {
    language: 'pseudo',
    label: 'Pseudo-code',
    code: `# Explicit ReAct format with structured output
SYSTEM_PROMPT = """
You are a ReAct agent. Always respond in this exact format:

Thought: [Your reasoning about the current situation]
Action: [tool_name(arg1, arg2)] OR Answer: [final response]
"""

function parseReactResponse(response):
    thought = extractBetween(response, "Thought:", "Action:")

    if contains(response, "Answer:"):
        answer = extractAfter(response, "Answer:")
        return { type: "complete", answer: answer }

    actionStr = extractAfter(response, "Action:")
    action = parseToolCall(actionStr)
    return { type: "action", thought: thought, action: action }

function reactLoop(task):
    messages = [systemPrompt, userMessage(task)]

    while true:
        response = llm.generate(messages)
        parsed = parseReactResponse(response)

        if parsed.type == "complete":
            return parsed.answer

        # Execute action and format observation
        result = execute(parsed.action)
        observation = f"Observation: {result}"

        messages.append(assistantMessage(response))
        messages.append(userMessage(observation))`,
  },
  {
    language: 'python',
    label: 'Python (LangChain)',
    code: `from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain.agents import AgentExecutor, create_react_agent
from langchain_core.tools import tool
from langchain import hub

# Define tools
@tool
def search(query: str) -> str:
    """Search the web for information."""
    return search_api.search(query)

@tool
def calculator(expression: str) -> str:
    """Evaluate a mathematical expression."""
    return str(eval(expression))

@tool
def lookup(term: str) -> str:
    """Look up a definition or fact."""
    return knowledge_base.lookup(term)

# Use LangChain's ReAct prompt (or customize your own)
prompt = hub.pull("hwchase17/react")

# Or create a custom ReAct prompt
custom_prompt = ChatPromptTemplate.from_messages([
    ("system", """You are a ReAct agent. Respond in this format:

Thought: [Your reasoning about what to do next]
Action: tool_name[input]
Observation: [Result from tool]
... (repeat until done)
Thought: I have the answer
Final Answer: [Your response]

Tools available: {tool_names}
{tools}"""),
    ("human", "{input}"),
    ("placeholder", "{agent_scratchpad}")
])

# Create the ReAct agent
llm = ChatOpenAI(model="gpt-4", temperature=0)
tools = [search, calculator, lookup]

agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=True,  # Shows Thought/Action/Observation trace
    max_iterations=10,
    handle_parsing_errors=True
)

# Run with visible reasoning trace
result = agent_executor.invoke({
    "input": "What's the population of Tokyo multiplied by 3?"
})
print(result["output"])`,
  },
  {
    language: 'csharp',
    label: 'C# (Semantic Kernel)',
    code: `using Microsoft.SemanticKernel;
using Microsoft.SemanticKernel.Planning;

public class ReActAgent
{
    private readonly Kernel _kernel;

    public ReActAgent(Kernel kernel)
    {
        _kernel = kernel;
    }

    public async Task<string> RunAsync(string task, int maxSteps = 10)
    {
        // Use Semantic Kernel's built-in planner for ReAct-style execution
        var planner = new FunctionCallingStepwisePlanner(
            new FunctionCallingStepwisePlannerOptions
            {
                MaxIterations = maxSteps,
                // Get reasoning traces in the result
                GetObservations = true
            }
        );

        var result = await planner.ExecuteAsync(_kernel, task);

        // Access the reasoning trace
        foreach (var step in result.ChatHistory)
        {
            Console.WriteLine($"Step: {step.Role}");
            Console.WriteLine($"Content: {step.Content}");
        }

        return result.FinalAnswer;
    }
}

// Setup kernel with plugins
var builder = Kernel.CreateBuilder();
builder.AddAzureOpenAIChatCompletion("gpt-4", endpoint, apiKey);

// Add tool plugins
builder.Plugins.AddFromType<SearchPlugin>();
builder.Plugins.AddFromType<CalculatorPlugin>();
builder.Plugins.AddFromType<LookupPlugin>();

var kernel = builder.Build();

// Run ReAct agent
var agent = new ReActAgent(kernel);
var answer = await agent.RunAsync(
    "What's the population of Tokyo multiplied by 3?"
);`,
  },
];

const modernReasoningExample = [
  {
    language: 'pseudo',
    label: 'Pseudo-code',
    code: `# Modern approach: Let reasoning models handle thinking internally
# No explicit "Thought:" prompting needed

function modernAgentLoop(task, tools):
    messages = [userMessage(task)]

    while true:
        response = reasoningModel.generate(
            messages: messages,
            tools: tools,
            # Reasoning model internally does CoT
            # No need to prompt for explicit thoughts
        )

        if response.hasToolCalls:
            for call in response.toolCalls:
                result = execute(call)
                messages.append(toolResult(call.id, result))
        else:
            # Model provides final answer directly
            return response.content

# Key insight: Models like o1, DeepSeek-R1, Claude 3.5
# have internalized reasoning - explicit CoT prompts
# can actually degrade performance by 3-5%`,
  },
  {
    language: 'python',
    label: 'Python (LangChain)',
    code: `from langgraph.prebuilt import create_react_agent
from langchain_anthropic import ChatAnthropic
from langchain_core.tools import tool

# Define tools
@tool
def search(query: str) -> str:
    """Search the web for information."""
    return search_api.search(query)

@tool
def calculator(expression: str) -> str:
    """Evaluate a mathematical expression."""
    return str(eval(expression))

# Modern LLMs have internalized reasoning
# LangGraph's create_react_agent handles the loop
llm = ChatAnthropic(model="claude-sonnet-4-20250514")
tools = [search, calculator]

# Create agent - framework handles ReAct internally
agent = create_react_agent(llm, tools)

def modern_agent(task: str) -> str:
    """
    Modern approach: LangGraph handles the ReAct loop.
    The model reasons internally - no explicit prompting needed.
    """
    result = agent.invoke({
        "messages": [("user", task)]
    })

    # Get the final response
    return result["messages"][-1].content

# For streaming with visible intermediate steps
async def modern_agent_stream(task: str):
    async for event in agent.astream_events(
        {"messages": [("user", task)]},
        version="v2"
    ):
        if event["event"] == "on_chat_model_stream":
            print(event["data"]["chunk"].content, end="")
        elif event["event"] == "on_tool_end":
            print(f"\\nTool result: {event['data']['output']}")`,
  },
  {
    language: 'csharp',
    label: 'C# (Semantic Kernel)',
    code: `using Microsoft.SemanticKernel;

public class ModernReActAgent
{
    private readonly Kernel _kernel;

    public ModernReActAgent(Kernel kernel)
    {
        _kernel = kernel;
    }

    public async Task<string> RunAsync(string task)
    {
        // Semantic Kernel handles the ReAct loop internally
        // with automatic function calling
        var settings = new OpenAIPromptExecutionSettings
        {
            FunctionChoiceBehavior = FunctionChoiceBehavior.Auto()
        };

        // The kernel automatically:
        // 1. Sends the prompt to the model
        // 2. Detects tool calls and executes them
        // 3. Feeds results back to the model
        // 4. Repeats until model gives final answer
        var result = await _kernel.InvokePromptAsync(
            task,
            new KernelArguments(settings)
        );

        return result.ToString();
    }
}

// Setup with plugins
var builder = Kernel.CreateBuilder();
builder.AddAzureOpenAIChatCompletion("gpt-4", endpoint, apiKey);
builder.Plugins.AddFromType<SearchPlugin>();
builder.Plugins.AddFromType<CalculatorPlugin>();
var kernel = builder.Build();

var agent = new ModernReActAgent(kernel);
var answer = await agent.RunAsync(
    "What's the population of Tokyo multiplied by 3?"
);

// Key insight: Modern frameworks abstract the ReAct loop
// The pattern is built into the infrastructure`,
  },
];
---

<BaseLayout
  title="ReAct Pattern"
  description="Learn the Reasoning + Acting pattern that forms the foundation of agentic AI behavior"
>
  <article class="max-w-4xl mx-auto px-4 sm:px-6 lg:px-8 py-12">
    <!-- Header -->
    <header class="mb-12">
      <nav class="mb-4">
        <a
          href="/agent-engineering/topics/"
          class="text-sm text-primary-600 dark:text-primary-400 hover:underline"
        >
          &larr; Back to Topics
        </a>
      </nav>
      <h1 class="text-3xl sm:text-4xl font-bold text-slate-900 dark:text-white mb-4">
        ReAct Pattern
      </h1>
      <p class="text-lg text-slate-600 dark:text-slate-300">
        Reasoning + Acting: The foundational loop that enables AI agents to think through problems and take action in the world.
      </p>
    </header>

    <!-- Concept Overview -->
    <section class="prose prose-slate dark:prose-invert max-w-none mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        What is ReAct?
      </h2>
      <p class="text-slate-600 dark:text-slate-300 mb-4">
        ReAct (Reasoning + Acting) is a prompting paradigm introduced by Yao et al. in 2022 that interleaves reasoning traces with actions. The key insight: by making the model explicitly reason about its actions, we get more reliable and interpretable agent behavior.
      </p>

      <Diagram title="The ReAct Loop">
{`┌─────────────────────────────────────────────────────────┐
│                      ReAct Loop                         │
└─────────────────────────────────────────────────────────┘
                          │
                          ▼
              ┌──────────────────────┐
              │       THOUGHT        │
              │  "I need to find..." │
              │  "The result shows..." │
              │  "Now I should..."   │
              └──────────────────────┘
                          │
                          ▼
              ┌──────────────────────┐
              │        ACTION        │
              │  search("query")     │
              │  calculate("2+2")    │
              │  lookup("term")      │
              └──────────────────────┘
                          │
                          ▼
              ┌──────────────────────┐
              │     OBSERVATION      │
              │  Result from tool    │
              │  or environment      │
              └──────────────────────┘
                          │
            ┌─────────────┴─────────────┐
            │                           │
            ▼                           ▼
    ┌───────────────┐          ┌───────────────┐
    │   Continue    │          │   Complete    │
    │   (loop back) │          │   (return)    │
    └───────────────┘          └───────────────┘`}
      </Diagram>

      <Callout type="info" title="Original Paper">
        ReAct was introduced in "ReAct: Synergizing Reasoning and Acting in Language Models" (Yao et al., 2022). It showed that combining reasoning traces with actions outperforms either approach alone.
      </Callout>
    </section>

    <!-- Basic Implementation -->
    <section class="mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        Basic ReAct Implementation
      </h2>
      <p class="text-slate-600 dark:text-slate-300 mb-4">
        The core ReAct pattern combines three elements in a loop: thinking about what to do, taking action, and observing the results.
      </p>

      <CodeBlock tabs={basicReactExample} title="ReAct Agent Loop" />
    </section>

    <!-- Explicit Reasoning -->
    <section class="mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        Explicit Reasoning Traces
      </h2>
      <p class="text-slate-600 dark:text-slate-300 mb-4">
        The original ReAct approach uses explicit text formatting to structure thoughts and actions. This makes the agent's reasoning visible and debuggable:
      </p>

      <CodeBlock tabs={explicitReasoningExample} title="Explicit ReAct Format" />

      <div class="mt-6 p-4 bg-slate-50 dark:bg-slate-800 rounded-lg">
        <h3 class="font-semibold text-slate-900 dark:text-white mb-2">
          Example Trace
        </h3>
        <pre class="text-sm text-slate-600 dark:text-slate-300 whitespace-pre-wrap font-mono">{`User: What's the population of Tokyo multiplied by 3?

Thought: I need to find the current population of Tokyo first.
Action: search(query="Tokyo population 2024")

Observation: Tokyo has a population of approximately 14 million people.

Thought: Now I have the population (14 million). I need to multiply by 3.
Action: calculator(expression="14000000 * 3")

Observation: 42000000

Thought: I have the answer. 14 million * 3 = 42 million.
Answer: The population of Tokyo (approximately 14 million) multiplied by 3 is 42 million.`}</pre>
      </div>
    </section>

    <!-- Evolution -->
    <section class="mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        Evolution: From Explicit to Implicit Reasoning
      </h2>

      <Table caption="ReAct has evolved as models have become more capable">
        <thead>
          <tr>
            <th>Era</th>
            <th>Approach</th>
            <th>Characteristics</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>2022-2023</strong></td>
            <td>Explicit ReAct</td>
            <td>Structured "Thought/Action/Observation" prompts</td>
          </tr>
          <tr>
            <td><strong>2023-2024</strong></td>
            <td>Tool-augmented LLMs</td>
            <td>Native function calling, implicit reasoning</td>
          </tr>
          <tr>
            <td><strong>2024-2025</strong></td>
            <td>Reasoning Models</td>
            <td>Internal chain-of-thought (o1, DeepSeek-R1, Claude)</td>
          </tr>
        </tbody>
      </Table>

      <Callout type="warning" title="Important Finding">
        Research shows that explicit Chain-of-Thought prompting can <em>degrade</em> performance by 3-5% on reasoning models like o1 and DeepSeek-R1. These models have internalized the reasoning process.
      </Callout>

      <CodeBlock tabs={modernReasoningExample} title="Modern Approach: Implicit Reasoning" />
    </section>

    <!-- When to Use Which -->
    <section class="mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        When to Use Each Approach
      </h2>

      <Table>
        <thead>
          <tr>
            <th>Scenario</th>
            <th>Recommended Approach</th>
            <th>Reason</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td>Debugging/Development</td>
            <td>Explicit ReAct</td>
            <td>Visible reasoning traces aid debugging</td>
          </tr>
          <tr>
            <td>Production with GPT-4</td>
            <td>Either</td>
            <td>Model supports both well</td>
          </tr>
          <tr>
            <td>Production with o1/R1</td>
            <td>Implicit (native tools)</td>
            <td>Explicit prompting hurts performance</td>
          </tr>
          <tr>
            <td>Open-source models</td>
            <td>Explicit ReAct</td>
            <td>More predictable behavior</td>
          </tr>
          <tr>
            <td>Compliance/Audit needs</td>
            <td>Explicit ReAct</td>
            <td>Full reasoning trail required</td>
          </tr>
        </tbody>
      </Table>
    </section>

    <!-- Evaluation -->
    <section class="mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        Evaluation Approach
      </h2>
      <p class="text-slate-600 dark:text-slate-300 mb-4">
        Evaluating ReAct agents requires measuring both the reasoning quality and task completion:
      </p>

      <Table caption="Key metrics for evaluating ReAct agents">
        <thead>
          <tr>
            <th>Metric</th>
            <th>What it Measures</th>
            <th>Target</th>
          </tr>
        </thead>
        <tbody>
          <tr>
            <td><strong>Task Completion</strong></td>
            <td>Did the agent achieve the goal?</td>
            <td>Binary or partial credit</td>
          </tr>
          <tr>
            <td><strong>Step Efficiency</strong></td>
            <td>Steps taken vs optimal path</td>
            <td>Lower is better</td>
          </tr>
          <tr>
            <td><strong>Reasoning Quality</strong></td>
            <td>Are thoughts logical and relevant?</td>
            <td>LLM-as-judge or human eval</td>
          </tr>
          <tr>
            <td><strong>Error Recovery</strong></td>
            <td>Can agent recover from mistakes?</td>
            <td>% successful recoveries</td>
          </tr>
          <tr>
            <td><strong>Hallucination Rate</strong></td>
            <td>Made-up facts in reasoning</td>
            <td>Lower is better</td>
          </tr>
        </tbody>
      </Table>

      <div class="mt-6 p-4 bg-slate-50 dark:bg-slate-800 rounded-lg">
        <h3 class="font-semibold text-slate-900 dark:text-white mb-2">
          Benchmarks
        </h3>
        <ul class="list-disc list-inside text-slate-600 dark:text-slate-300 space-y-1">
          <li><strong>HotpotQA</strong> - Multi-hop reasoning questions</li>
          <li><strong>FEVER</strong> - Fact verification requiring evidence</li>
          <li><strong>ALFWorld</strong> - Embodied agent tasks</li>
          <li><strong>WebShop</strong> - Web navigation and shopping</li>
          <li><strong>SWE-bench</strong> - Software engineering tasks</li>
        </ul>
      </div>
    </section>

    <!-- Common Pitfalls -->
    <section class="mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        Common Pitfalls
      </h2>

      <div class="space-y-4">
        <Callout type="danger" title="Infinite Loops">
          Without proper termination conditions, agents can loop indefinitely. Always set maximum step limits and detect repetitive behavior.
        </Callout>

        <Callout type="danger" title="Reasoning-Action Mismatch">
          The model might state an intention in its thought but take a different action. Validate that actions align with stated reasoning.
        </Callout>

        <Callout type="warning" title="Over-thinking">
          Some tasks don't need multi-step reasoning. Don't force the ReAct pattern on simple queries that could be answered directly.
        </Callout>

        <Callout type="warning" title="Lost Context">
          In long traces, the model may forget earlier observations. Consider summarizing history or using memory systems.
        </Callout>
      </div>
    </section>

    <!-- Trajectory Analysis -->
    <section class="mb-12">
      <h2 class="text-2xl font-bold text-slate-900 dark:text-white mb-4">
        Trajectory Analysis & Debugging
      </h2>
      <p class="text-slate-600 dark:text-slate-300 mb-4">
        One of ReAct's key benefits is interpretability. You can analyze agent trajectories to understand failures:
      </p>

      <Diagram title="Trajectory Analysis">
{`Trajectory: Weather Query
─────────────────────────────────────────────────────
Step 1 │ Thought: Need weather for NYC
       │ Action:  search("NYC weather")
       │ Result:  ✓ Got weather data
─────────────────────────────────────────────────────
Step 2 │ Thought: Need to convert to Celsius
       │ Action:  calculator("75 - 32 * 5/9")  ← BUG!
       │ Result:  ✗ Wrong formula (missing parens)
─────────────────────────────────────────────────────
Step 3 │ Thought: Result seems wrong, retry
       │ Action:  calculator("(75 - 32) * 5/9")
       │ Result:  ✓ Correct conversion
─────────────────────────────────────────────────────

Analysis:
- Model caught its own error (good recovery)
- Root cause: Math formatting issue
- Fix: Add examples to calculator tool description`}
      </Diagram>

      <Callout type="tip" title="Best Practice">
        Log full trajectories in production. When failures occur, the trace shows exactly where and why the agent went wrong, making debugging straightforward.
      </Callout>
    </section>

    <!-- Next Steps -->
    <section class="border-t border-slate-200 dark:border-slate-700 pt-8">
      <h2 class="text-xl font-bold text-slate-900 dark:text-white mb-4">
        Related Topics
      </h2>
      <div class="grid sm:grid-cols-2 gap-4">
        <a
          href="/agent-engineering/topics/tool-use/"
          class="block p-4 bg-slate-50 dark:bg-slate-800 rounded-lg hover:bg-slate-100 dark:hover:bg-slate-700 transition-colors"
        >
          <h3 class="font-semibold text-slate-900 dark:text-white mb-1">Tool Use & Function Calling</h3>
          <p class="text-sm text-slate-600 dark:text-slate-400">
            The ACTION component of ReAct - how tools are defined and called
          </p>
        </a>
        <a
          href="/agent-engineering/topics/memory/"
          class="block p-4 bg-slate-50 dark:bg-slate-800 rounded-lg hover:bg-slate-100 dark:hover:bg-slate-700 transition-colors"
        >
          <h3 class="font-semibold text-slate-900 dark:text-white mb-1">Memory Systems</h3>
          <p class="text-sm text-slate-600 dark:text-slate-400">
            Extend ReAct with persistent memory for multi-session agents
          </p>
        </a>
      </div>
    </section>
  </article>
</BaseLayout>
